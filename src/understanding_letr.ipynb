{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n",
    "    print(int(os.environ[\"RANK\"]))\n",
    "    print(int(os.environ['WORLD_SIZE']))\n",
    "    print(int(os.environ['LOCAL_RANK']))\n",
    "elif 'SLURM_PROCID' in os.environ:\n",
    "    print(int(os.environ['SLURM_PROCID']))\n",
    "    print( torch.cuda.device_count())\n",
    "else:\n",
    "    print('Not using distributed mode')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel computing is a minor issue for now that needs to be solved eventually, Pytorch lightning integration might be useful."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets seem to keeo COCO annotation format with a json file with an \"annotations\" key and corresponding value \"0\" for lines. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: difference between id and category id in coco:\n",
    "\n",
    "    - categories are classes (or labels) of objects that are present in an image.\n",
    "    - category_id : This maps the category that an object belongs to.\n",
    "    - image_id : This is the mapping with the image that the object is related to. \n",
    "    - id : This is a unique identifier that identifies each annotation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load some images and look at ground truth annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = DATADIR / \"wireframe_processed\"\n",
    "mode = 'lines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = {\n",
    "            \"train\": (root / \"train2017\", root / \"annotations\" / f'{mode}_train2017.json'),\n",
    "            \"val\": (root / \"val2017\", root / \"annotations\" / f'{mode}_val2017.json'),\n",
    "        }    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first look at the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_set = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder, ann_file = PATHS[image_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.coco import ConvertCocoPolysToMask, make_coco_transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fix path issue when loading local module.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "import datasets.transforms as T\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, img_folder, ann_file, transforms, args, quit=False):\n",
    "        super(CocoDetection, self).__init__(img_folder, ann_file)\n",
    "        self._transforms = transforms\n",
    "        self.prepare = ConvertCocoPolysToMask() \n",
    "        self.args = args\n",
    "        self.quit = quit\n",
    "    def __getitem__(self, idx):\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        img, target = self.prepare(img, target, self.args)\n",
    "        if self.quit:\n",
    "            return img, target\n",
    "         \n",
    "        if self._transforms is not None:\n",
    "            print(\"transforming img\")\n",
    "            img, new_target = self._transforms(img, target)\n",
    "        return img, new_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyArgs:\n",
    "    def __init__(self, dictionary):\n",
    "        self.__dict__ = dictionary\n",
    "    \n",
    "    def __getattr__(self, key):\n",
    "        return self.__dict__[key]\n",
    "my_dict = {\"eval\": False, \"coco_path\": \"../data/wireframe_processed\"}\n",
    "args = MyArgs(my_dict)\n",
    "print(args.eval) # output: John"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datasets import build_dataset\n",
    "train_dataset = build_dataset(image_set='train', args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset = CocoDetection(img_folder, ann_file, transforms=make_coco_transforms(image_set, args), args=args, quit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "img = prepare_dataset[i][0]\n",
    "img_lines = prepare_dataset[i][1][\"lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset[0][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_lines.max())\n",
    "print(img_lines.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset[0][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = prepare_dataset[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(img)\n",
    "for tp_id, line in enumerate(img_lines):\n",
    "    x1,y1, x2, y2 = line.numpy() # this is xyxy # TODO: check why the output of the network is inverted\n",
    "    p1 = (x1, y1)\n",
    "    p2 = (x2, y2)\n",
    "    plt.plot([p1[0], p2[0]], [p1[1], p2[1]], linewidth=1, color='red', zorder=1)\n",
    "# plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flipping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_image = F.hflip(img)\n",
    "\n",
    "w, h = img.size\n",
    "\n",
    "\n",
    "lines = img_lines.clone()\n",
    "lines = lines[:, [2, 3, 0, 1]] * torch.as_tensor([-1, 1, -1, 1]) + torch.as_tensor([w, 0, w, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(flipped_image)\n",
    "for tp_id, line in enumerate(lines):\n",
    "    x1,y1, x2, y2 = line.numpy() # this is xyxy # TODO: check why the output of the network is inverted\n",
    "    p1 = (x1, y1)\n",
    "    p2 = (x2, y2)\n",
    "    plt.plot([p1[0], p2[0]], [p1[1], p2[1]], linewidth=1, color='red', zorder=1)\n",
    "# plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CocoDetection(img_folder, ann_file, transforms=make_coco_transforms(image_set, args), args=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_dataset[i][0]\n",
    "# img_lines_new = dataset[0][1][\"lines\"]\n",
    "target =  train_dataset[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[\"size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[\"orig_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[\"lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h, img_w = target[\"orig_size\"].unbind(0)\n",
    "scale_fct = torch.unsqueeze(torch.stack([img_w, img_h, img_w, img_h], dim=0), dim=0)\n",
    "lines = target[\"lines\"] * scale_fct[:, None, :]\n",
    "# lines = lines.view(1000, 2, 2)\n",
    "# lines = lines.flip([-1])# this is yxyx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[\"lines\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in lines:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lines(lines, ax):\n",
    "    for tp_id, line in enumerate(lines.squeeze()):\n",
    "        x1,y1, x2, y2 = line.numpy() # this is xyxy # TODO: check why the output of the network is inverted\n",
    "        p1 = (x1, y1)\n",
    "        p2 = (x2, y2)\n",
    "        ax.plot([p1[0], p2[0]], [p1[1], p2[1]], linewidth=1, color='red', zorder=1)\n",
    "fig, axes = plt.subplots(1, 2, figsize = (20, 20))\n",
    "axes[0].imshow(img.permute(1,2,0))\n",
    "plot_lines(lines, axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.axis('off')\n",
    "fig = plt.figure()\n",
    "for tp_id, line in enumerate(target[\"lines\"].squeeze()):\n",
    "    x1,y1, x2, y2 = line.numpy() # this is xyxy # TODO: check why the output of the network is inverted\n",
    "    # y1, x1, y2, x2 = line.numpy() # this is yxyx\n",
    "    p1 = (x1 , y1 )\n",
    "    p2 = (x2 , y2 )\n",
    "    plt.plot([p1[0], p2[0]], [p1[1], p2[1]], linewidth=1, color='red', zorder=1)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "letr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
